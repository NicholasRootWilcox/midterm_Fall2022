{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicholasRootWilcox/midterm_Fall2022/blob/main/WILCOX_Nicholas_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4db07fbe",
      "metadata": {
        "id": "4db07fbe"
      },
      "outputs": [],
      "source": [
        "## INSTALLING DATA\n",
        "## for data\n",
        "import pandas as pd\n",
        "\n",
        "## ashdgfjkawdfnv;lkansdfv[kpjawfklvhjafsk'vn'\n",
        "## askhvajvb]\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "## for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "## for statistical tests\n",
        "import scipy\n",
        "#import statsmodels.formula.api as smf\n",
        "#import statsmodels.api as sm\n",
        "\n",
        "## for machine learning\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection, preprocessing, feature_selection, ensemble, linear_model, metrics, decomposition\n",
        "\n",
        "# Import Gaussian Naive Bayes classifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Import Evaluation Metric\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "## for explainer\n",
        "#from lime import lime_tabular\n",
        "\n",
        "\n",
        "!pip3 install pandas\n",
        "\n",
        "\n",
        "#https://towardsdatascience.com/machine-learning-with-python-classification-complete-tutorial-d2c99dc524ec\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import pandas as pd \n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_moons, make_circles, make_classification\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.inspection import DecisionBoundaryDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c8d2a7b",
      "metadata": {
        "id": "9c8d2a7b"
      },
      "outputs": [],
      "source": [
        "## for data\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# LOAD DATA \n",
        "# Convert dataset to a pandas dataframe:\n",
        "dataset = pd.read_csv('CSV_aquila_table1.csv') \n",
        "print(dataset.columns)\n",
        "print(dataset)\n"
      ],
      "metadata": {
        "id": "6Q5RjyjhZJQl"
      },
      "id": "6Q5RjyjhZJQl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "E4y6JheWPaTh"
      },
      "id": "E4y6JheWPaTh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7690a55",
      "metadata": {
        "id": "b7690a55",
        "outputId": "0f84c8aa-bebc-46e1-b311-05ca5d504af1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['#', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# TASK: LOAD DATA THAT WAS GIVEN TO YOU\n",
        "# Convert dataset to a pandas dataframe\n",
        "dataset = pd.read_csv('CSV_aquila_table1.csv') ## tsv = csv but separeated by tabs\n",
        "\n",
        "print(dataset.columns)\n",
        "## DATASET type = 'object', 5 indexes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# TASK: INSPECT DATA\n",
        "print(\"----------------------------------------------------------------------\")\n",
        "\n",
        "print(f\"DATASET EMPTY: \\t\\t{dataset.empty}\") # Empty\n",
        "print(f\"DATASET SHAPE:  \\t{dataset.shape}\") # Attribute\n",
        "print(f\"DATASET SIZE: \\t\\t{dataset.size}\") # Empty\n",
        "print(\"----------------------------------------------------------------------\")\n",
        "print(f\"DATASET ISNULL VALUE: \\t{dataset.isnull().sum()}\") # Is Null? \n",
        "print(\"----------------------------------------------------------------------\")\n",
        "print(f\"TOTAL MISSING: \\t{dataset.isnull().sum().sum()}\") # Total Missing\n",
        "print(\"----------------------------------------------------------------------\")\n",
        "print(f\"DATASET HEAD: \\n{dataset.head()}\") # Method\n",
        "print(\"----------------------------------------------------------------------\")\n",
        "print(f\"DATASET TYPES: \\t{dataset.dtypes}\") # Types\n",
        "print(\"----------------------------------------------------------------------\")\n",
        "print(f\"DATASET TYPES: \\t{dataset.info()}\") # Info \n",
        "print(f\"DATASET COL: \\t{dataset.columns}\") # Col names\n",
        "print(\"----------------------------------------------------------------------\")\n",
        "print(f\"DATASET TAIL: \\t{dataset.tail()}\") # TAIL\n",
        "print(\"----------------------------------------------------------------------\")\n",
        "##print(f\"DATASET MIN: \\t{dataset['ColumnName'].max()}\")\n",
        "\n",
        "##print('MIN = \\t\\t\\t\\t\\t', np.min(dataset)) \n",
        "print(dataset.min(numeric_only=True))\n",
        "print(dataset.max(numeric_only=True))\n",
        "print(dataset.mean(numeric_only=True))\n",
        "print(dataset.range(numeric_only=True))\n",
        "\n",
        "\n",
        "# Plot histogram,boxplots, heatmap\n",
        "# Check variable stasttics\n",
        "# Check NaN values, etc.\n",
        "# Visualize correlation\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rpFklfjpYClF",
        "outputId": "2e7f17a6-ecc1-4246-969e-28754eef17a4"
      },
      "id": "rpFklfjpYClF",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------\n",
            "DATASET EMPTY: \t\tFalse\n",
            "DATASET SHAPE:  \t(917, 5)\n",
            "DATASET SIZE: \t\t4585\n",
            "----------------------------------------------------------------------\n",
            "DATASET ISNULL VALUE: \t#               1\n",
            "Unnamed: 1    842\n",
            "Unnamed: 2    848\n",
            "Unnamed: 3    849\n",
            "Unnamed: 4    849\n",
            "dtype: int64\n",
            "----------------------------------------------------------------------\n",
            "TOTAL MISSING: \t3389\n",
            "----------------------------------------------------------------------\n",
            "DATASET HEAD: \n",
            "                                                   #               Unnamed: 1  \\\n",
            "0  #   VizieR Astronomical Server vizier.cds.unis...                      NaN   \n",
            "1            #    Date: 2022-10-11T14:49:59 [V7.293]                      NaN   \n",
            "2          #   In case of problem, please report to:  cds-question@unistra.fr   \n",
            "3                                                  #                      NaN   \n",
            "4                                                  #                      NaN   \n",
            "\n",
            "  Unnamed: 2 Unnamed: 3 Unnamed: 4  \n",
            "0        NaN        NaN        NaN  \n",
            "1        NaN        NaN        NaN  \n",
            "2        NaN        NaN        NaN  \n",
            "3        NaN        NaN        NaN  \n",
            "4        NaN        NaN        NaN  \n",
            "----------------------------------------------------------------------\n",
            "DATASET TYPES: \t#             object\n",
            "Unnamed: 1    object\n",
            "Unnamed: 2    object\n",
            "Unnamed: 3    object\n",
            "Unnamed: 4    object\n",
            "dtype: object\n",
            "----------------------------------------------------------------------\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 917 entries, 0 to 916\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   #           916 non-null    object\n",
            " 1   Unnamed: 1  75 non-null     object\n",
            " 2   Unnamed: 2  69 non-null     object\n",
            " 3   Unnamed: 3  68 non-null     object\n",
            " 4   Unnamed: 4  68 non-null     object\n",
            "dtypes: object(5)\n",
            "memory usage: 35.9+ KB\n",
            "DATASET TYPES: \tNone\n",
            "DATASET COL: \tIndex(['#', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], dtype='object')\n",
            "----------------------------------------------------------------------\n",
            "DATASET TAIL: \t                                                     # Unnamed: 1 Unnamed: 2  \\\n",
            "912  745;183652.5-021914;18 36 52.50;-02 19 14.4;  ...        NaN        NaN   \n",
            "913  746;183652.7-021215;18 36 52.77;-02 12 15.7;  ...        NaN        NaN   \n",
            "914  747;183652.9-021440;18 36 52.95;-02 14 40.7;  ...        NaN        NaN   \n",
            "915  748;183654.2-021242;18 36 54.24;-02 12 42.7;  ...        NaN        NaN   \n",
            "916  749;183703.2-021240;18 37 03.28;-02 12 40.6;  ...        NaN        NaN   \n",
            "\n",
            "    Unnamed: 3 Unnamed: 4  \n",
            "912        NaN        NaN  \n",
            "913        NaN        NaN  \n",
            "914        NaN        NaN  \n",
            "915        NaN        NaN  \n",
            "916        NaN        NaN  \n",
            "----------------------------------------------------------------------\n",
            "Series([], dtype: float64)\n",
            "Series([], dtype: float64)\n",
            "Series([], dtype: float64)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-a812d36e8a75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'range'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# TASK: DATA ENGINEERING, FEATURE ENGINEERING\n",
        "# Use head() function to return the first 5 rows: \n",
        "print(dataset.head()) \n",
        "# Assign values to the X and y variables:\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, 4].values \n",
        "X = dataset[['sepal.length', 'sepal.width', 'petal.length', 'petal.width']]\n",
        "y = dataset['variety']\n",
        "\n",
        "print(\"Summary Statistics of the X dataframe \\n\", X.describe())\n",
        "\n"
      ],
      "metadata": {
        "id": "3fYJFVKpYGO0"
      },
      "id": "3fYJFVKpYGO0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Split dataset into random train and test subsets:\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30) \n",
        "\n",
        "\n",
        "print(X.shape, y.shape)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "Vn9Be3sqYJx5"
      },
      "id": "Vn9Be3sqYJx5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Standardizing variable\n",
        "#Instruction: This step is optional\n",
        "# You can use non, one or all of these scalers to find better model, \n",
        "# i.e. models with better accuracy & precision.\n",
        "# For other scaling or feature engineering methods, check this ref:\n",
        "# https://scikit-learn.org/stable/modules/classes.html?highlight=sklearn+preprocessing#module-sklearn.preprocessing\n",
        "\n"
      ],
      "metadata": {
        "id": "K226Jbn_YMm8"
      },
      "id": "K226Jbn_YMm8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Standardize features by removing mean and scaling to unit variance:\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test) \n",
        "\n",
        "X_train_df = pd.DataFrame(X_train)\n",
        "print(\"\\n Summary Statistics of the X dataframe after Standard Scaling\\n\", X_train_df.describe())\n",
        "\n"
      ],
      "metadata": {
        "id": "EK7VYmqaYRau"
      },
      "id": "EK7VYmqaYRau",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# MinmaxScaling features by removing mean and scaling to unit variance:\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test) \n",
        "\n",
        "X_train_df = pd.DataFrame(X_train)\n",
        "print(\"\\n Summary Statistics of the X dataframe after MinMaxScaler Scaling\\n\", X_train_df.describe())\n",
        "\n"
      ],
      "metadata": {
        "id": "cMxoBIqOYTG-"
      },
      "id": "cMxoBIqOYTG-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# SELECT MODEL\n",
        "# classifiers = [\n",
        "#    KNeighborsClassifier(n_neighbors=3),\n",
        "#    DecisionTreeClassifier(max_depth=5),\n",
        "#    SVC(kernel=\"linear\", C=0.025),\n",
        "#    SVC(gamma=2, C=1),\n",
        "#    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
        "#    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "#    MLPClassifier(alpha=1, max_iter=1000),\n",
        "#    AdaBoostClassifier(),\n",
        "#    GaussianNB(),\n",
        "#    QuadraticDiscriminantAnalysis(),\n",
        "#]\n",
        "\n"
      ],
      "metadata": {
        "id": "jtn0RUnxYUeg"
      },
      "id": "jtn0RUnxYUeg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# TASK:\n",
        "# Initialize classifier\n",
        "# Choose 3 classifers\n",
        "# Check the paramters of these classifiers using sklearn manuals\n",
        "# Change the paramters manualy or by using for loop to choose the better model (model with better metrics)\n",
        "\n"
      ],
      "metadata": {
        "id": "LZw9f6BtYWfI"
      },
      "id": "LZw9f6BtYWfI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Use the KNN classifier to fit data:\n",
        "classifier = KNeighborsClassifier(n_neighbors=3)  \n",
        "\n"
      ],
      "metadata": {
        "id": "5uVh07CzYXe0"
      },
      "id": "5uVh07CzYXe0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Gaussian Process Classifier\n",
        "classifier = DecisionTreeClassifier(max_depth=5)  \n",
        "\n"
      ],
      "metadata": {
        "id": "AYsgr_4TYYkU"
      },
      "id": "AYsgr_4TYYkU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Support Vector Machine\n",
        "classifier = SVC(kernel=\"linear\", C=0.025)\n",
        "\n"
      ],
      "metadata": {
        "id": "W6497WmaYa7c"
      },
      "id": "W6497WmaYa7c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Support Vector Machine\n",
        "classifier = SVC(gamma=2, C=1)  \n"
      ],
      "metadata": {
        "id": "Sc9TAjUSYchV"
      },
      "id": "Sc9TAjUSYchV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Gaussian Process Classifier\n",
        "classifier = GaussianProcessClassifier(1.0 * RBF(1.0)) \n"
      ],
      "metadata": {
        "id": "vccqlwSfYdbc"
      },
      "id": "vccqlwSfYdbc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# RandomForestClassifier\n",
        "classifier = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n"
      ],
      "metadata": {
        "id": "7_WfzYkJYeRu"
      },
      "id": "7_WfzYkJYeRu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# MLPClassifier\n",
        "classifier = MLPClassifier(alpha=1, max_iter=1000)\n",
        "\n"
      ],
      "metadata": {
        "id": "-OlDsecBYfAK"
      },
      "id": "-OlDsecBYfAK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# AdaBoostClassifier\n",
        "classifier = AdaBoostClassifier()\n",
        "\n"
      ],
      "metadata": {
        "id": "E7TptZCPYgTI"
      },
      "id": "E7TptZCPYgTI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# GnB\n",
        "classifier = GaussianNB()  \n",
        "\n"
      ],
      "metadata": {
        "id": "w-l3MFUEYk3w"
      },
      "id": "w-l3MFUEYk3w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# QuadraticDiscriminantAnalysis\n",
        "classifier = QuadraticDiscriminantAnalysis()\n"
      ],
      "metadata": {
        "id": "Wz428DdaYmAv"
      },
      "id": "Wz428DdaYmAv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "#TRAIN MODEL\n",
        "classifier.fit(X_train, y_train)  # Train the classifier\n"
      ],
      "metadata": {
        "id": "ifoKAhjfYm52"
      },
      "id": "ifoKAhjfYm52",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# TASK: PREDICT NEW VALUES\n",
        "# Predict y data with classifier: \n",
        "y_predict = classifier.predict(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "YfxyBu8WYn8b"
      },
      "id": "YfxyBu8WYn8b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#TASK: EVALUATE RESULTS\n",
        "# Print results: \n",
        "print(confusion_matrix(y_test, y_predict))\n",
        "print(classification_report(y_test, y_predict)) \n"
      ],
      "metadata": {
        "id": "mfeU-JGQYpdV"
      },
      "id": "mfeU-JGQYpdV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Evaluate label (subsets) accuracy\n",
        "print(accuracy_score(y_test, y_predict))\n",
        "\n",
        "print(y_test, y_predict)"
      ],
      "metadata": {
        "id": "3MLlvUvGYrld"
      },
      "id": "3MLlvUvGYrld",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4d3f636",
      "metadata": {
        "id": "b4d3f636"
      },
      "outputs": [],
      "source": [
        "# Tip for modularization\n",
        "https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py\n",
        "\n",
        "\n",
        "\n",
        "#https://towardsdatascience.com/machine-learning-with-python-classification-complete-tutorial-d2c99dc524ec"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}