{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicholasRootWilcox/midterm_Fall2022/blob/main/WILCOX_Nicholas_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "4db07fbe",
      "metadata": {
        "id": "4db07fbe",
        "outputId": "833c8487-3167-4b33-e333-96b5e87fe77a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-ad50e43338a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminant_analysis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuadraticDiscriminantAnalysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minspection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionBoundaryDisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'DecisionBoundaryDisplay' from 'sklearn.inspection' (/usr/local/lib/python3.7/dist-packages/sklearn/inspection/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "## INSTALLING DATA\n",
        "## for data\n",
        "import pandas as pd\n",
        "\n",
        "## ashdgfjkawdfnv;lkansdfv[kpjawfklvhjafsk'vn'\n",
        "## askhvajvb]\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "## for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "## for statistical tests\n",
        "import scipy\n",
        "#import statsmodels.formula.api as smf\n",
        "#import statsmodels.api as sm\n",
        "\n",
        "## for machine learning\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection, preprocessing, feature_selection, ensemble, linear_model, metrics, decomposition\n",
        "\n",
        "# Import Gaussian Naive Bayes classifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Import Evaluation Metric\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "## for explainer\n",
        "#from lime import lime_tabular\n",
        "\n",
        "\n",
        "!pip3 install pandas\n",
        "\n",
        "\n",
        "#https://towardsdatascience.com/machine-learning-with-python-classification-complete-tutorial-d2c99dc524ec\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import pandas as pd \n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_moons, make_circles, make_classification\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.inspection import DecisionBoundaryDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "9c8d2a7b",
      "metadata": {
        "id": "9c8d2a7b"
      },
      "outputs": [],
      "source": [
        "## for data\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD DATA \n",
        "# Convert dataset to a pandas dataframe:\n",
        "dataset = pd.read_csv('aquila_table1.tsv', delimiter=';',comment='#')\n",
        "X = dataset[['Signi070', 'Sp070', 'e_Sp070',\n",
        "       'Sp070/Sbg070', 'Sconv070', 'Stot070', 'e_Stot070', 'FWHMa070',\n",
        "       'FWHMb070', 'PA070', 'Signi160', 'Sp160', 'e_Sp160', 'Sp160/Sbg160',\n",
        "       'Sconv160', 'Stot160', 'e_Stot160', 'FWHMa160', 'FWHMb160', 'PA160',\n",
        "       'Signi250', 'Sp250', 'e_Sp250', 'Sp250/Sbg250', 'Sconv250', 'Stot250',\n",
        "       'e_Stot250', 'FWHMa250', 'FWHMb250', 'PA250', 'Signi350', 'Sp350',\n",
        "       'e_Sp350', 'Sp350/Sbg350', 'Sconv350', 'Stot350', 'e_Stot350',\n",
        "       'FWHMa350', 'FWHMb350', 'PA350', 'Signi500', 'Sp500', 'e_Sp500',\n",
        "       'Sp500/Sbg500', 'Stot500', 'e_Stot500', 'FWHMa500', 'FWHMb500', 'PA500',\n",
        "       'SigniNH2', 'NpH2', 'NpH2/Nbg', 'NconvH2', 'NbgH2', 'FWHMaNH2',\n",
        "       'FWHMbNH2', 'PANH2', 'NSED', 'CSARflag']]\n",
        "y = dataset['Coretype']\n",
        "print(dataset.columns)\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q5RjyjhZJQl",
        "outputId": "58eadd94-5c07-40ac-c6c2-39b77b3539df"
      },
      "id": "6Q5RjyjhZJQl",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Seq', 'Name', 'RAJ2000', 'DEJ2000', 'Signi070', 'Sp070', 'e_Sp070',\n",
            "       'Sp070/Sbg070', 'Sconv070', 'Stot070', 'e_Stot070', 'FWHMa070',\n",
            "       'FWHMb070', 'PA070', 'Signi160', 'Sp160', 'e_Sp160', 'Sp160/Sbg160',\n",
            "       'Sconv160', 'Stot160', 'e_Stot160', 'FWHMa160', 'FWHMb160', 'PA160',\n",
            "       'Signi250', 'Sp250', 'e_Sp250', 'Sp250/Sbg250', 'Sconv250', 'Stot250',\n",
            "       'e_Stot250', 'FWHMa250', 'FWHMb250', 'PA250', 'Signi350', 'Sp350',\n",
            "       'e_Sp350', 'Sp350/Sbg350', 'Sconv350', 'Stot350', 'e_Stot350',\n",
            "       'FWHMa350', 'FWHMb350', 'PA350', 'Signi500', 'Sp500', 'e_Sp500',\n",
            "       'Sp500/Sbg500', 'Stot500', 'e_Stot500', 'FWHMa500', 'FWHMb500', 'PA500',\n",
            "       'SigniNH2', 'NpH2', 'NpH2/Nbg', 'NconvH2', 'NbgH2', 'FWHMaNH2',\n",
            "       'FWHMbNH2', 'PANH2', 'NSED', 'CSARflag', 'Coretype', 'NSIMBAD',\n",
            "       'NSPITZER', 'Com', 'Simbad'],\n",
            "      dtype='object')\n",
            "     Seq             Name      RAJ2000      DEJ2000  Signi070    Sp070  \\\n",
            "0      1  182154.6-025557  18 21 54.63  -02 55 57.2       0.0  0.00825   \n",
            "1      2  182215.5-030107  18 22 15.58  -03 01 07.9       0.0  0.03570   \n",
            "2      3  182246.4-032847  18 22 46.43  -03 28 47.8       2.5 -0.03080   \n",
            "3      4  182254.4-033415  18 22 54.46  -03 34 15.6       0.0  0.01500   \n",
            "4      5  182303.8-032358  18 23 03.86  -03 23 58.0       0.0  0.00736   \n",
            "..   ...              ...          ...          ...       ...      ...   \n",
            "744  745  183652.5-021914  18 36 52.50  -02 19 14.4       0.1 -0.01500   \n",
            "745  746  183652.7-021215  18 36 52.77  -02 12 15.7       0.0  0.00381   \n",
            "746  747  183652.9-021440  18 36 52.95  -02 14 40.7       0.0  0.00217   \n",
            "747  748  183654.2-021242  18 36 54.24  -02 12 42.7       1.4 -0.01200   \n",
            "748  749  183703.2-021240  18 37 03.28  -02 12 40.6       0.0  0.00300   \n",
            "\n",
            "     e_Sp070  Sp070/Sbg070  Sconv070  Stot070  ...  FWHMaNH2 FWHMbNH2 PANH2  \\\n",
            "0      0.015          0.20   0.10200 -0.19500  ...        40       22    36   \n",
            "1      0.015          0.82   0.44100  0.09030  ...        32       22   107   \n",
            "2      0.015         -0.62  -0.38000 -0.00871  ...        39       23   123   \n",
            "3      0.015          0.02   0.00569  0.10100  ...        28       26   177   \n",
            "4      0.015          0.14   0.06140  0.00919  ...        31       21    76   \n",
            "..       ...           ...       ...      ...  ...       ...      ...   ...   \n",
            "744    0.015         -0.07  -0.00578  0.03510  ...        41       27   160   \n",
            "745    0.015          0.09   0.06520 -0.48800  ...        48       35    37   \n",
            "746    0.015          0.05   0.02060 -0.18400  ...        27       23   118   \n",
            "747    0.015         -0.29  -0.04450  0.00996  ...        33       18   186   \n",
            "748    0.015          0.07   0.01150  0.14400  ...        30       21    94   \n",
            "\n",
            "    NSED  CSARflag      Coretype                            NSIMBAD  \\\n",
            "0      2         0  starless                                          \n",
            "1      2         0  starless                                          \n",
            "2      2         0  starless                                          \n",
            "3      2         2  starless                                          \n",
            "4      2         2  prestellar                                        \n",
            "..   ...       ...           ...                                ...   \n",
            "744    4         2  prestellar                                        \n",
            "745    4         1  starless                                          \n",
            "746    3         2  prestellar                                        \n",
            "747    3         0  prestellar                                        \n",
            "748    4         2  prestellar                                        \n",
            "\n",
            "                   NSPITZER            Com  Simbad  \n",
            "0                                           Simbad  \n",
            "1                                           Simbad  \n",
            "2                                           Simbad  \n",
            "3                                           Simbad  \n",
            "4                                           Simbad  \n",
            "..                      ...            ...     ...  \n",
            "744                          CO high-V_LSR  Simbad  \n",
            "745                          CO high-V_LSR  Simbad  \n",
            "746                          CO high-V_LSR  Simbad  \n",
            "747                          CO high-V_LSR  Simbad  \n",
            "748                          CO high-V_LSR  Simbad  \n",
            "\n",
            "[749 rows x 68 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Nicholas\n",
        "dataset = pd.read_csv('aquila_table1.tsv', delimiter=';',comment='#')\n",
        "X = dataset[['Signi070', 'Sp070', 'e_Sp070',\n",
        "       'Sp070/Sbg070', 'Sconv070', 'Stot070', 'e_Stot070', 'FWHMa070',\n",
        "       'FWHMb070', 'PA070', 'Signi160', 'Sp160', 'e_Sp160', 'Sp160/Sbg160',\n",
        "       'Sconv160', 'Stot160', 'e_Stot160', 'FWHMa160', 'FWHMb160', 'PA160',\n",
        "       'Signi250', 'Sp250', 'e_Sp250', 'Sp250/Sbg250', 'Sconv250', 'Stot250',\n",
        "       'e_Stot250', 'FWHMa250', 'FWHMb250', 'PA250', 'Signi350', 'Sp350',\n",
        "       'e_Sp350', 'Sp350/Sbg350', 'Sconv350', 'Stot350', 'e_Stot350',\n",
        "       'FWHMa350', 'FWHMb350', 'PA350', 'Signi500', 'Sp500', 'e_Sp500',\n",
        "       'Sp500/Sbg500', 'Stot500', 'e_Stot500', 'FWHMa500', 'FWHMb500', 'PA500',\n",
        "       'SigniNH2', 'NpH2', 'NpH2/Nbg', 'NconvH2', 'NbgH2', 'FWHMaNH2',\n",
        "       'FWHMbNH2', 'PANH2', 'NSED', 'CSARflag']]\n",
        "y = dataset['Coretype']"
      ],
      "metadata": {
        "id": "yxFxk3ZRJpEt"
      },
      "id": "yxFxk3ZRJpEt",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "E4y6JheWPaTh"
      },
      "id": "E4y6JheWPaTh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7690a55",
      "metadata": {
        "id": "b7690a55"
      },
      "outputs": [],
      "source": [
        "\n",
        "# TASK: LOAD DATA THAT WAS GIVEN TO YOU\n",
        "# Convert dataset to a pandas dataframe\n",
        "dataset = pd.read_csv('aquila_table1.tsv', delimiter=';',comment='#')\n",
        "X = dataset[['Signi070', 'Sp070', 'e_Sp070',\n",
        "       'Sp070/Sbg070', 'Sconv070', 'Stot070', 'e_Stot070', 'FWHMa070',\n",
        "       'FWHMb070', 'PA070', 'Signi160', 'Sp160', 'e_Sp160', 'Sp160/Sbg160',\n",
        "       'Sconv160', 'Stot160', 'e_Stot160', 'FWHMa160', 'FWHMb160', 'PA160',\n",
        "       'Signi250', 'Sp250', 'e_Sp250', 'Sp250/Sbg250', 'Sconv250', 'Stot250',\n",
        "       'e_Stot250', 'FWHMa250', 'FWHMb250', 'PA250', 'Signi350', 'Sp350',\n",
        "       'e_Sp350', 'Sp350/Sbg350', 'Sconv350', 'Stot350', 'e_Stot350',\n",
        "       'FWHMa350', 'FWHMb350', 'PA350', 'Signi500', 'Sp500', 'e_Sp500',\n",
        "       'Sp500/Sbg500', 'Stot500', 'e_Stot500', 'FWHMa500', 'FWHMb500', 'PA500',\n",
        "       'SigniNH2', 'NpH2', 'NpH2/Nbg', 'NconvH2', 'NbgH2', 'FWHMaNH2',\n",
        "       'FWHMbNH2', 'PANH2', 'NSED', 'CSARflag']]\n",
        "y = dataset['Coretype']\n",
        "print(dataset.columns)\n",
        "## DATASET type = 'object', 5 indexes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# TASK: INSPECT DATA\n",
        "print(\"----------------------------------------------------------------------\")\n",
        "\n",
        "print(f\"DATASET EMPTY: \\t\\t{dataset.empty}\") # Empty\n",
        "print(f\"DATASET SHAPE:  \\t{dataset.shape}\") # Attribute\n",
        "print(f\"DATASET SIZE: \\t\\t{dataset.size}\") # Empty\n",
        "print(\"----------------------------------------------------------------------\")\n",
        "print(f\"DATASET ISNULL VALUE: \\t{dataset.isnull().sum()}\") # Is Null? \n",
        "print(\"----------------------------------------------------------------------\")\n",
        "print(f\"TOTAL MISSING: \\t{dataset.isnull().sum().sum()}\") # Total Missing\n",
        "print(\"----------------------------------------------------------------------\")\n",
        "print(f\"DATASET HEAD: \\n{dataset.head()}\") # Method\n",
        "print(\"----------------------------------------------------------------------\")\n",
        "print(f\"DATASET TYPES: \\t{dataset.dtypes}\") # Types\n",
        "print(\"----------------------------------------------------------------------\")\n",
        "print(f\"DATASET TYPES: \\t{dataset.info()}\") # Info \n",
        "print(\"----------------------------------------------------------------------\")\n",
        "print(f\"DATASET COL: \\t{dataset.columns}\") # Col names\n",
        "print(\"----------------------------------------------------------------------\")\n",
        "print(f\"DATASET TAIL: \\t{dataset.tail()}\") # TAIL\n",
        "print(\"----------------------------------------------------------------------\")\n",
        "\n",
        "##print(f\"DATASET MIN: \\t{dataset['ColumnName'].max()}\")\n",
        "\n",
        "##print('MIN = \\t\\t\\t\\t\\t', np.min(dataset)) \n",
        "\n",
        "print(\"....................................\")\n",
        "print(\"....................................\")\n",
        "print(\"....................................\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rpFklfjpYClF"
      },
      "id": "rpFklfjpYClF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## PROBLEM NUMBER 2 --- INCOMPLETE"
      ],
      "metadata": {
        "id": "mt2YCFxtyFLw"
      },
      "id": "mt2YCFxtyFLw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot histogram,boxplots, heatmap\n",
        "# Check variable stasttics\n",
        "# Check NaN values, etc.\n",
        "# Visualize correlation\n",
        "\n",
        "#write along the lines of not possible\n",
        "#rename columns after getting an idea of what they are\n",
        "\n",
        "\n",
        "my_squeezed_image = dataset.squeeze();\n",
        "plt.imshow(my_squeezed_image)"
      ],
      "metadata": {
        "id": "20lC9XhOyUik"
      },
      "id": "20lC9XhOyUik",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# TASK: DATA ENGINEERING, FEATURE ENGINEERING\n",
        "# Use head() function to return the first 5 rows: \n",
        "print(dataset.head()) \n",
        "# Assign values to the X and y variables:\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, 4].values \n",
        "X = dataset[['Signi070', 'Sp070', 'e_Sp070',\n",
        "       'Sp070/Sbg070', 'Sconv070', 'Stot070', 'e_Stot070', 'FWHMa070',\n",
        "       'FWHMb070', 'PA070', 'Signi160', 'Sp160', 'e_Sp160', 'Sp160/Sbg160',\n",
        "       'Sconv160', 'Stot160', 'e_Stot160', 'FWHMa160', 'FWHMb160', 'PA160',\n",
        "       'Signi250', 'Sp250', 'e_Sp250', 'Sp250/Sbg250', 'Sconv250', 'Stot250',\n",
        "       'e_Stot250', 'FWHMa250', 'FWHMb250', 'PA250', 'Signi350', 'Sp350',\n",
        "       'e_Sp350', 'Sp350/Sbg350', 'Sconv350', 'Stot350', 'e_Stot350',\n",
        "       'FWHMa350', 'FWHMb350', 'PA350', 'Signi500', 'Sp500', 'e_Sp500',\n",
        "       'Sp500/Sbg500', 'Stot500', 'e_Stot500', 'FWHMa500', 'FWHMb500', 'PA500',\n",
        "       'SigniNH2', 'NpH2', 'NpH2/Nbg', 'NconvH2', 'NbgH2', 'FWHMaNH2',\n",
        "       'FWHMbNH2', 'PANH2', 'NSED', 'CSARflag']]\n",
        "Y = dataset['Coretype']\n",
        "\n",
        "\n",
        "print(\"Summary Statistics of the X dataframe \\n\", X.describe())\n",
        "\n"
      ],
      "metadata": {
        "id": "3fYJFVKpYGO0"
      },
      "id": "3fYJFVKpYGO0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Split dataset into random train and test subsets:\n",
        "print(\"TEST SIZE = 30%\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30) \n",
        "\n",
        "\n",
        "print(X.shape, y.shape)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)\n",
        "\n",
        "print(\"--\")\n",
        "print(\"TEST SIZE = 20%\")\n",
        "print(\"--\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
        "\n",
        "print(X.shape, y.shape)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "Vn9Be3sqYJx5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2067e42c-5a99-44c3-c69a-718b0348939f"
      },
      "id": "Vn9Be3sqYJx5",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST SIZE = 30%\n",
            "(749, 59) (749,)\n",
            "(524, 59) (524,)\n",
            "(225, 59) (225,)\n",
            "--\n",
            "TEST SIZE = 20%\n",
            "--\n",
            "(749, 59) (749,)\n",
            "(599, 59) (599,)\n",
            "(150, 59) (150,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Standardizing variable\n",
        "#Instruction: This step is optional\n",
        "# You can use non, one or all of these scalers to find better model, \n",
        "# i.e. models with better accuracy & precision.\n",
        "# For other scaling or feature engineering methods, check this ref:\n",
        "# https://scikit-learn.org/stable/modules/classes.html?highlight=sklearn+preprocessing#module-sklearn.preprocessing\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K226Jbn_YMm8"
      },
      "id": "K226Jbn_YMm8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Standardize features by removing mean and scaling to unit variance:\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test) \n",
        "\n",
        "X_train_dataset = pd.DataFrame(X_train)\n",
        "print(\"\\n Summary Statistics of the X dataframe after Standard Scaling\\n\", X_train_df.describe())\n",
        "\n"
      ],
      "metadata": {
        "id": "EK7VYmqaYRau"
      },
      "id": "EK7VYmqaYRau",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# MinmaxScaling features by removing mean and scaling to unit variance:\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test) \n",
        "\n",
        "X_train_df = pd.DataFrame(X_train)\n",
        "print(\"\\n Summary Statistics of the X dataframe after MinMaxScaler Scaling\\n\", X_train_df.describe())\n",
        "\n"
      ],
      "metadata": {
        "id": "cMxoBIqOYTG-"
      },
      "id": "cMxoBIqOYTG-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# SELECT MODEL\n",
        "# classifiers = [\n",
        "#    KNeighborsClassifier(n_neighbors=3),\n",
        "#    DecisionTreeClassifier(max_depth=5),\n",
        "#    SVC(kernel=\"linear\", C=0.025),\n",
        "#    SVC(gamma=2, C=1),\n",
        "#    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
        "#    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "#    MLPClassifier(alpha=1, max_iter=1000),\n",
        "#    AdaBoostClassifier(),\n",
        "#    GaussianNB(),\n",
        "#    QuadraticDiscriminantAnalysis(),\n",
        "#]\n",
        "\n"
      ],
      "metadata": {
        "id": "jtn0RUnxYUeg"
      },
      "id": "jtn0RUnxYUeg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# TASK:\n",
        "# Initialize classifier\n",
        "# Choose 3 classifers\n",
        "# Check the paramters of these classifiers using sklearn manuals\n",
        "# Change the paramters manualy or by using for loop to choose the better model (model with better metrics)\n",
        "\n"
      ],
      "metadata": {
        "id": "LZw9f6BtYWfI"
      },
      "id": "LZw9f6BtYWfI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Use the KNN classifier to fit data:\n",
        "classifier = KNeighborsClassifier(n_neighbors=3)  \n",
        "\n"
      ],
      "metadata": {
        "id": "5uVh07CzYXe0"
      },
      "id": "5uVh07CzYXe0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Gaussian Process Classifier\n",
        "classifier = DecisionTreeClassifier(max_depth=5)  \n",
        "\n"
      ],
      "metadata": {
        "id": "AYsgr_4TYYkU"
      },
      "id": "AYsgr_4TYYkU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Support Vector Machine\n",
        "classifier = SVC(kernel=\"linear\", C=0.025)\n",
        "\n"
      ],
      "metadata": {
        "id": "W6497WmaYa7c"
      },
      "id": "W6497WmaYa7c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Support Vector Machine\n",
        "classifier = SVC(gamma=2, C=1)  \n"
      ],
      "metadata": {
        "id": "Sc9TAjUSYchV"
      },
      "id": "Sc9TAjUSYchV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Gaussian Process Classifier\n",
        "classifier = GaussianProcessClassifier(1.0 * RBF(1.0)) \n"
      ],
      "metadata": {
        "id": "vccqlwSfYdbc"
      },
      "id": "vccqlwSfYdbc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# RandomForestClassifier\n",
        "classifier = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n"
      ],
      "metadata": {
        "id": "7_WfzYkJYeRu"
      },
      "id": "7_WfzYkJYeRu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# MLPClassifier\n",
        "classifier = MLPClassifier(alpha=1, max_iter=1000)\n",
        "\n"
      ],
      "metadata": {
        "id": "-OlDsecBYfAK"
      },
      "id": "-OlDsecBYfAK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# AdaBoostClassifier\n",
        "classifier = AdaBoostClassifier()\n",
        "\n"
      ],
      "metadata": {
        "id": "E7TptZCPYgTI"
      },
      "id": "E7TptZCPYgTI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# GnB\n",
        "classifier = GaussianNB()  \n",
        "\n"
      ],
      "metadata": {
        "id": "w-l3MFUEYk3w"
      },
      "id": "w-l3MFUEYk3w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# QuadraticDiscriminantAnalysis\n",
        "classifier = QuadraticDiscriminantAnalysis()\n"
      ],
      "metadata": {
        "id": "Wz428DdaYmAv"
      },
      "id": "Wz428DdaYmAv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "#TRAIN MODEL\n",
        "classifier.fit(X_train, y_train)  # Train the classifier\n"
      ],
      "metadata": {
        "id": "ifoKAhjfYm52"
      },
      "id": "ifoKAhjfYm52",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# TASK: PREDICT NEW VALUES\n",
        "# Predict y data with classifier: \n",
        "y_predict = classifier.predict(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "YfxyBu8WYn8b"
      },
      "id": "YfxyBu8WYn8b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#TASK: EVALUATE RESULTS\n",
        "# Print results: \n",
        "print(confusion_matrix(y_test, y_predict))\n",
        "print(classification_report(y_test, y_predict)) \n"
      ],
      "metadata": {
        "id": "mfeU-JGQYpdV"
      },
      "id": "mfeU-JGQYpdV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Evaluate label (subsets) accuracy\n",
        "print(accuracy_score(y_test, y_predict))\n",
        "\n",
        "print(y_test, y_predict)"
      ],
      "metadata": {
        "id": "3MLlvUvGYrld"
      },
      "id": "3MLlvUvGYrld",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4d3f636",
      "metadata": {
        "id": "b4d3f636"
      },
      "outputs": [],
      "source": [
        "# Tip for modularization\n",
        "https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py\n",
        "\n",
        "\n",
        "\n",
        "#https://towardsdatascience.com/machine-learning-with-python-classification-complete-tutorial-d2c99dc524ec"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}